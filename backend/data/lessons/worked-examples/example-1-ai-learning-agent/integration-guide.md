# Integration Guide: AI Learning Agent

> –ö–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å AI Learning Agent –¥–ª—è —Å–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

## üéØ –î–ª—è –∫–æ–≥–æ —ç—Ç–æ—Ç –≥–∞–π–¥

–≠—Ç–æ—Ç –≥–∞–π–¥ –ø–æ–º–æ–∂–µ—Ç –≤–∞–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å AI Learning Agent (–∏–ª–∏ –µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã) –≤:
- üìö **–û–Ω–ª–∞–π–Ω-—à–∫–æ–ª—É** ‚Äî –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
- üìñ **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é** ‚Äî AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ docs
- üè¢ **–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —É—á–µ–±–Ω—ã–π –ø–æ—Ä—Ç–∞–ª
- üíº **–õ—é–±–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ** —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º + AI-–ø–æ–º–æ—â–Ω–∏–∫–æ–º

## üîß –£—Ä–æ–≤–Ω–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### Level 1: –ü–æ–ª–Ω–∞—è –∫–æ–ø–∏—è (Easiest)

–ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –∫–æ–Ω—Ç–µ–Ω—Ç.

**–ß—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å:**

1. **–ó–∞–º–µ–Ω–∏—Ç–µ –∫–æ–Ω—Ç–µ–Ω—Ç** –≤ `backend/data/lessons/`
```bash
# –£–¥–∞–ª–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã
rm -rf backend/data/lessons/ai-web-learning
rm -rf backend/data/lessons/project-setup-guide

# –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–∏ –∫—É—Ä—Å—ã
mkdir backend/data/lessons/my-course
# –°–æ–∑–¥–∞–π—Ç–µ .md —Ñ–∞–π–ª—ã —Å –≤–∞—à–∏–º–∏ —É—Ä–æ–∫–∞–º–∏
```

2. **–û–±–Ω–æ–≤–∏—Ç–µ boundaries** –≤ `backend/prompts/boundaries.md`
```markdown
# Knowledge Boundaries

## What I Know

### My Course Name (XX lessons)

**Module 1:** Topic 1 (5 lessons)
- Lesson 1.1: Title
- Lesson 1.2: Title
...
```

3. **–ù–∞—Å—Ç—Ä–æ–π—Ç–µ system prompt** –≤ `backend/prompts/system_prompt.md`
```markdown
# AI Tutor System Prompt

You are an AI tutor for [YOUR DOMAIN] with access to course materials.
Your role is to help students learn [YOUR TOPIC]...
```

4. **–û–±–Ω–æ–≤–∏—Ç–µ .env —Ñ–∞–π–ª—ã**
```env
# backend/.env
OPENROUTER_API_KEY=your_key_here
```

5. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ**
```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload

# Frontend
cd frontend
npm install
npm run dev
```

**–ì–æ—Ç–æ–≤–æ!** –£ –≤–∞—Å –µ—Å—Ç—å AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –≤–∞—à–µ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.

---

### Level 2: Backend Only (Medium)

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ backend API, —Å–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–π frontend.

**–®–∞–≥–∏:**

1. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ backend** (—Å–º. Level 1, —à–∞–≥–∏ 1-4)

2. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoints:**

```javascript
// Your custom frontend

// Get available models
const models = await fetch('http://localhost:8000/api/models')

// Get lessons structure
const lessons = await fetch('http://localhost:8000/api/lessons')

// Chat with AI
const response = await fetch('http://localhost:8000/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: "User's question",
    lesson_ids: ["course/module/lesson-1", "course/module/lesson-2"],
    model: "google/gemini-2.5-flash-preview-09-2025",
    history: []  // Optional conversation history
  })
})

const data = await response.json()
// data.response - AI's answer
// data.model_used - Model that answered
// data.tokens_used - Token usage
```

3. **–°–æ–∑–¥–∞–π—Ç–µ —Å–≤–æ–π UI:**
- –í–∞—à –¥–∏–∑–∞–π–Ω
- –í–∞—à–∞ –Ω–∞–≤–∏–≥–∞—Ü–∏—è
- –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ UI
- ‚úÖ –ú–æ–∂–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
- ‚úÖ Backend handling AI logic

---

### Level 3: Specific Components (Advanced)

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã.

#### 3.1. –¢–æ–ª—å–∫–æ Prompt System

**Use case:** –£ –≤–∞—Å —É–∂–µ –µ—Å—Ç—å AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è, –Ω—É–∂–Ω–∞ Markdown-based –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è.

**–ß—Ç–æ –≤–∑—è—Ç—å:**
```
backend/
‚îú‚îÄ‚îÄ prompts/                    # Copy this
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt.md
‚îÇ   ‚îú‚îÄ‚îÄ boundaries.md
‚îÇ   ‚îî‚îÄ‚îÄ model_settings.md
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ prompt_loader.py        # Copy this
‚îî‚îÄ‚îÄ config.py                   # Adapt PROMPTS_DIR
```

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
```python
from services.prompt_loader import PromptLoader

# Initialize
prompt_loader = PromptLoader("path/to/prompts")

# Load prompt
system_prompt = prompt_loader.load_system_prompt()

# Build with context
full_prompt = prompt_loader.build_full_prompt(context="Your context here")

# Use with your AI API
response = your_ai_api.generate(full_prompt, user_message)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Easy prompt editing (Markdown files)
- ‚úÖ Git version control for prompts
- ‚úÖ SSOT principle (Lesson 1.7)

---

#### 3.2. –¢–æ–ª—å–∫–æ OpenRouter Service

**Use case:** –ù—É–∂–Ω–∞ multi-model –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å fallback.

**–ß—Ç–æ –≤–∑—è—Ç—å:**
```
backend/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ openrouter_service.py   # Copy this
‚îî‚îÄ‚îÄ config.py                   # Copy AVAILABLE_MODELS
```

**–ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
```python
from services.openrouter_service import OpenRouterService
from services.prompt_loader import PromptLoader

# Initialize
prompt_loader = PromptLoader("prompts/")
openrouter = OpenRouterService(
    api_key="your-key",
    api_base="https://openrouter.ai/api/v1",
    default_model="google/gemini-2.5-flash-preview-09-2025",
    fallback_model="x-ai/grok-4-fast",
    prompt_loader=prompt_loader,
    model_configs=YOUR_MODEL_CONFIGS
)

# Use
response = await openrouter.chat(
    message="User question",
    context="Your context",
    model="google/gemini-2.5-flash-preview-09-2025"
)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Multiple AI models (Gemini, Claude, GPT, Grok)
- ‚úÖ Automatic fallback if model fails
- ‚úÖ Model-specific settings (temperature, max_tokens)

---

#### 3.3. –¢–æ–ª—å–∫–æ Three-Panel Layout

**Use case:** –ù—É–∂–µ–Ω Claude-style UI –¥–ª—è —Å–≤–æ–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.

**–ß—Ç–æ –≤–∑—è—Ç—å:**
```
frontend/src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ layout/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AppLayout.jsx       # Copy this
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResizeHandle.jsx    # Copy this
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ResizeHandle.css
‚îÇ   ‚îî‚îÄ‚îÄ [adapt other components]
‚îî‚îÄ‚îÄ index.css                   # Copy color scheme
```

**–ö–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å:**
```jsx
import AppLayout from './components/layout/AppLayout'

function App() {
  return (
    <AppLayout
      leftPanel={<YourLeftSidebar />}
      centerPanel={<YourMainContent />}
      rightPanel={<YourRightSidebar />}  // Optional
    />
  )
}
```

**CSS Variables:**
```css
:root {
  --bg-primary: #1e1e1e;
  --bg-secondary: #252525;
  --text-primary: #e0e0e0;
  --accent-primary: #f97316;  /* Your brand color */
}
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Professional Claude-style layout
- ‚úÖ Resizable panels
- ‚úÖ Dark theme
- ‚úÖ Responsive design

---

## üìö Use Case Examples

### Example 1: –û–Ω–ª–∞–π–Ω-—à–∫–æ–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –°—Ç—É–¥–µ–Ω—Ç—ã —É—á–∞—Ç Python, –Ω—É–∂–µ–Ω AI-–ø–æ–º–æ—â–Ω–∏–∫.

**–†–µ—à–µ–Ω–∏–µ:** Level 1 (Full Copy)

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –ó–∞–º–µ–Ω–∏—Ç—å —É—Ä–æ–∫–∏ –Ω–∞ –∫—É—Ä—Å –ø–æ Python
2. –û–±–Ω–æ–≤–∏—Ç—å `system_prompt.md`:
   ```markdown
   You are an AI tutor for Python programming.
   Help students learn Python by answering questions based on course materials.
   ```
3. –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
   ```markdown
   ## Guidelines
   - Always show code examples
   - Explain concepts step-by-step
   - Encourage students to try code themselves
   ```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Students select Python lessons
- ‚úÖ AI answers based on course materials
- ‚úÖ Multi-model support (choose fastest/cheapest)

---

### Example 2: –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–º–ø–∞–Ω–∏–∏

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ë–æ–ª—å—à–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è, —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º —Å–ª–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç—ã.

**–†–µ—à–µ–Ω–∏–µ:** Level 2 (Backend Only)

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
1. Backend:
   - –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∫–∞–∫ "lessons" –≤ `backend/data/lessons/company-docs/`
   - –û–±–Ω–æ–≤–∏—Ç—å `boundaries.md` —Å–æ —Å–ø–∏—Å–∫–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
2. Frontend:
   - –°–æ–∑–¥–∞—Ç—å –º–∏–Ω–∏–º–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π UI (–ø—Ä–æ—Å—Ç–æ search bar + chat)
   - –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ—Ä—Ç–∞–ª

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Employees ask questions
- ‚úÖ AI answers from company docs
- ‚úÖ Faster onboarding, less support tickets

---

### Example 3: –£–∂–µ –µ—Å—Ç—å AI, –Ω—É–∂–Ω–∞ –ª—É—á—à–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**–°—Ü–µ–Ω–∞—Ä–∏–π:** AI —É–∂–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω, –Ω–æ prompt hardcoded, —Å–ª–æ–∂–Ω–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å.

**–†–µ—à–µ–Ω–∏–µ:** Level 3.1 (Prompt System Only)

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å `prompt_loader.py`
2. –°–æ–∑–¥–∞—Ç—å `prompts/` –ø–∞–ø–∫—É —Å Markdown —Ñ–∞–π–ª–∞–º–∏
3. –ó–∞–º–µ–Ω–∏—Ç—å hardcoded prompt –Ω–∞ `prompt_loader.build_full_prompt()`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Prompts –≤ Git
- ‚úÖ –õ–µ–≥–∫–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å (–æ—Ç–∫—Ä—ã—Ç—å .md —Ñ–∞–π–ª)
- ‚úÖ Follows SSOT principle (Lesson 1.7)

---

### Example 4: Multi-model support –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

**–°—Ü–µ–Ω–∞—Ä–∏–π:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç–µ —Ç–æ–ª—å–∫–æ OpenAI, —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å Gemini/Claude.

**–†–µ—à–µ–Ω–∏–µ:** Level 3.2 (OpenRouter Service Only)

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å `openrouter_service.py`
2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å `AVAILABLE_MODELS` –≤ config
3. –ó–∞–º–µ–Ω–∏—Ç—å `openai.chat()` –Ω–∞ `openrouter_service.chat()`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Users choose model
- ‚úÖ Automatic fallback if model fails
- ‚úÖ Save costs (use cheapest model)

---

## üîê Security Considerations

### 1. API Keys

**‚ùå NEVER commit .env files to Git**
```gitignore
# .gitignore
.env
```

**‚úÖ Use .env.example for documentation**
```env
# .env.example
OPENROUTER_API_KEY=your_key_here
```

### 2. CORS Configuration

**Restrict allowed origins:**
```python
# backend/config.py
ALLOWED_ORIGINS = [
    "https://your-production-domain.com",
    "http://localhost:5173"  # Only for development
]
```

### 3. Rate Limiting

**Add rate limiting for production:**
```python
from fastapi import FastAPI
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/chat")
@limiter.limit("10/minute")  # Max 10 requests per minute
async def chat(request: ChatRequest):
    ...
```

### 4. Input Validation

**Already implemented with Pydantic:**
```python
class ChatRequest(BaseModel):
    message: str = Field(..., max_length=5000)  # Limit message length
    lesson_ids: List[str] = Field(..., max_items=20)  # Limit lessons
```

---

## üí∞ Cost Optimization

### 1. Choose Right Model

**For cost-sensitive applications:**
```python
DEFAULT_MODEL = "x-ai/grok-4-fast"  # Affordable: $0.05 in / $0.15 out per 1M
FALLBACK_MODEL = "google/gemini-2.5-flash-preview-09-2025"  # Very cheap
```

**For quality-sensitive applications:**
```python
DEFAULT_MODEL = "anthropic/claude-sonnet-4.5"  # Best quality
FALLBACK_MODEL = "google/gemini-2.5-flash-preview-09-2025"  # Good quality, cheaper
```

### 2. Limit Context Length

**Only load selected lessons:**
```python
# Good: User selects 3 lessons
context = context_service.get_context(["lesson-1", "lesson-2", "lesson-3"])

# Bad: Load all 72 lessons
# context = context_service.get_context(all_lesson_ids)  # ‚ùå Too expensive
```

### 3. Cache Responses

**Add caching for common questions:**
```python
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_response(question: str, context_hash: str):
    # Return cached response if exists
    ...
```

### 4. Use Lower Temperature

**Lower temperature = fewer tokens:**
```python
"temperature": 0.3,  # More deterministic, cheaper
"max_tokens": 2000   # Limit response length
```

---

## üöÄ Deployment

### Option 1: Traditional Hosting

**Backend (FastAPI):**
```bash
# Install dependencies
pip install -r requirements.txt

# Run with Gunicorn (production)
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

**Frontend (React):**
```bash
# Build for production
npm run build

# Serve with nginx or any static host
# Output: dist/ folder
```

**Platforms:**
- Railway.app (easiest for FastAPI)
- Vercel (for frontend)
- DigitalOcean, AWS, Google Cloud

---

### Option 2: Docker

**Create Dockerfile for backend:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Create Dockerfile for frontend:**
```dockerfile
FROM node:18-alpine as build

WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=build /app/dist /usr/share/nginx/html
```

**Docker Compose:**
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - ./backend/.env

  frontend:
    build: ./frontend
    ports:
      - "80:80"
    depends_on:
      - backend
```

---

## üìä Monitoring & Analytics

### Add Logging

**Already implemented:**
```python
import logging
logger = logging.getLogger(__name__)

logger.info(f"Sending request to OpenRouter with model: {model}")
logger.debug(f"Context length: {len(context)} characters")
logger.error(f"API error: {e}")
```

### Track Usage

**Add to ChatResponse:**
```python
class ChatResponse(BaseModel):
    response: str
    model_used: str
    tokens_used: Optional[int]
    context_length: int
    timestamp: datetime  # Add this
```

**Store in database or log:**
```python
# Log usage for analytics
usage_logger.info({
    "user_id": user_id,
    "model": model_used,
    "tokens": tokens_used,
    "timestamp": datetime.now()
})
```

---

## üîó –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
- [Overview](overview.md) - –û–±—â–∏–π –æ–±–∑–æ—Ä
- [Architecture](architecture.md) - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã
- [Implementation](implementation.md) - –î–µ—Ç–∞–ª–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
- [Lessons Applied](lessons-applied.md) - –ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ —É—Ä–æ–∫–∏

### –í–Ω–µ—à–Ω–∏–µ —Ä–µ—Å—É—Ä—Å—ã
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)
- [OpenRouter API Docs](https://openrouter.ai/docs)
- [Vite Documentation](https://vitejs.dev/)

### –ö—É—Ä—Å—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ)
- [Lesson 1.7: Documentation](../../../project-setup-guide/1-fundamentals/1.7%20–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:%20–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è%20–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è.md) - SSOT principles
- [Lesson 1.1: Project Organization](../../../project-setup-guide/1-fundamentals/1.1%20–§–∏–ª–æ—Å–æ—Ñ–∏—è%20–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π%20–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏%20–ø—Ä–æ–µ–∫—Ç–∞.md) - Separation of Concerns
- [Lesson 9.6: Gemini AI Agent](../../../ai-web-learning/9-rag-ai/lesson-9-6-gemini-ai-agent.md) - AI integration

---

## üí¨ –ü–æ–¥–¥–µ—Ä–∂–∫–∞

**–í–æ–ø—Ä–æ—Å—ã –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏?**
- –ò–∑—É—á–∏—Ç–µ [architecture.md](architecture.md) –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
- –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ [implementation.md](implementation.md) –¥–ª—è –¥–µ—Ç–∞–ª–µ–π –∫–æ–¥–∞
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ [lessons-applied.md](lessons-applied.md) –¥–ª—è –∫–æ–Ω—Ü–µ–ø—Ü–∏–π

**–ù–∞—à–ª–∏ –±–∞–≥?**
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ backend: `uvicorn main:app --reload --log-level debug`
- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ console frontend: F12 ‚Üí Console

---

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-10-16

**–£–¥–∞—á–∏ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π! üöÄ**

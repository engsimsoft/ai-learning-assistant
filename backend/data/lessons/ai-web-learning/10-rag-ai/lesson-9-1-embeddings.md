# –£—Ä–æ–∫ 9.1: –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î –∏ Embeddings

> **–ú–æ–¥—É–ª—å 9:** RAG + AI –ê–≥–µ–Ω—Ç  
> **–£—Ä–æ–∫:** 9.1  
> **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** 2.5 —á–∞—Å–∞  
> **Prerequisite:** –£—Ä–æ–∫ 9.0

---

## üéØ –¶–µ–ª–∏ —É—Ä–æ–∫–∞

–ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ —É—Ä–æ–∫–∞ —Ç—ã —Å–º–æ–∂–µ—à—å:
- ‚úÖ –ü–æ–Ω–∏–º–∞—Ç—å —á—Ç–æ —Ç–∞–∫–æ–µ embeddings (–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è)
- ‚úÖ –ó–Ω–∞—Ç—å –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç semantic search (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫)
- ‚úÖ –ü–æ–Ω–∏–º–∞—Ç—å —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –æ–±—ã—á–Ω–æ–π –ë–î –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π
- ‚úÖ –í—ã–±–∏—Ä–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î (pgvector vs Pinecone vs ChromaDB)
- ‚úÖ –°–æ–∑–¥–∞–≤–∞—Ç—å embeddings –¥–ª—è —Å–≤–æ–∏—Ö —É—Ä–æ–∫–æ–≤ —Å OpenAI API
- ‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î

---

## üìñ –ß–∞—Å—Ç—å 1: –ß—Ç–æ —Ç–∞–∫–æ–µ Embeddings?

### –ì–ª–∞–≤–Ω—ã–π –≤–æ–ø—Ä–æ—Å

**"–ö–∞–∫ –∫–æ–º–ø—å—é—Ç–µ—Ä –ø–æ–Ω–∏–º–∞–µ—Ç —Å–º—ã—Å–ª —Ç–µ–∫—Å—Ç–∞?"**

### –ü—Ä–æ–±–ª–µ–º–∞: –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –Ω–µ –ø–æ–Ω–∏–º–∞—é—Ç —Å–ª–æ–≤–∞

**–î–ª—è —á–µ–ª–æ–≤–µ–∫–∞:**
```
"–∫–æ—Ç" ‚âà "–∫–æ—à–∫–∞" ‚âà "–∫–æ—Ç—ë–Ω–æ–∫"  (–ø–æ—Ö–æ–∂–∏–π —Å–º—ã—Å–ª)
"–∫–æ—Ç" ‚â† "—Å–æ–±–∞–∫–∞"              (—Ä–∞–∑–Ω—ã–π —Å–º—ã—Å–ª)
```

**–î–ª—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞:**
```
"–∫–æ—Ç"    = —Å—Ç—Ä–æ–∫–∞ –∏–∑ 3 —Å–∏–º–≤–æ–ª–æ–≤
"–∫–æ—à–∫–∞"  = —Å—Ç—Ä–æ–∫–∞ –∏–∑ 5 —Å–∏–º–≤–æ–ª–æ–≤
"–∫–æ—Ç—ë–Ω–æ–∫" = —Å—Ç—Ä–æ–∫–∞ –∏–∑ 7 —Å–∏–º–≤–æ–ª–æ–≤

–ö–æ–º–ø—å—é—Ç–µ—Ä –Ω–µ –∑–Ω–∞–µ—Ç —á—Ç–æ –æ–Ω–∏ —Å–≤—è–∑–∞–Ω—ã!
```

### –†–µ—à–µ–Ω–∏–µ: Embeddings

**–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**
Embedding = –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª (–≤–µ–∫—Ç–æ—Ä), –≥–¥–µ –ø–æ—Ö–æ–∂–∏–π —Å–º—ã—Å–ª = –ø–æ—Ö–æ–∂–∏–µ —á–∏—Å–ª–∞.

**–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
```
"–∫–æ—Ç"     ‚Üí [0.8,  0.3, -0.1,  0.5, ...]  (1536 —á–∏—Å–µ–ª)
"–∫–æ—à–∫–∞"   ‚Üí [0.79, 0.31, -0.09, 0.48, ...] (–ø–æ—Ö–æ–∂–∏–µ —á–∏—Å–ª–∞!)
"–∫–æ—Ç—ë–Ω–æ–∫" ‚Üí [0.81, 0.29, -0.11, 0.52, ...] (—Ç–æ–∂–µ –±–ª–∏–∑–∫–æ!)

"—Å–æ–±–∞–∫–∞"  ‚Üí [0.7, -0.2,  0.4, -0.3, ...]  (–¥—Ä—É–≥–∏–µ —á–∏—Å–ª–∞)
"–º–∞—à–∏–Ω–∞"  ‚Üí [-0.1, 0.8, -0.5,  0.2, ...]  (—Å–æ–≤—Å–µ–º –¥—Ä—É–≥–∏–µ!)
```

### –ö–∞–∫ —Å–æ–∑–¥–∞—é—Ç—Å—è embeddings?

**Neural Network (–Ω–µ–π—Ä–æ—Å–µ—Ç—å) –æ–±—É—á–µ–Ω–∞:**
```
–ü—Ä–æ—á–∏—Ç–∞–ª–∞ –º–∏–ª–ª–∏–∞—Ä–¥—ã —Ç–µ–∫—Å—Ç–æ–≤
        ‚Üì
–ü–æ–Ω—è–ª–∞ —á—Ç–æ:
- "–∫–æ—Ç" –∏ "–∫–æ—à–∫–∞" –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –ø–æ—Ö–æ–∂–∏—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö
- "–∫–æ—Ç –º—É—Ä–ª—ã–∫–∞–µ—Ç", "–∫–æ—à–∫–∞ –º—É—Ä–ª—ã–∫–∞–µ—Ç"
- "–∫–æ—Ç –ª–æ–≤–∏—Ç –º—ã—à–µ–π", "–∫–æ—à–∫–∞ –ª–æ–≤–∏—Ç –º—ã—à–µ–π"
        ‚Üì
–°–æ–∑–¥–∞—ë—Ç –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä—ã –¥–ª—è "–∫–æ—Ç" –∏ "–∫–æ—à–∫–∞"
```

### –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –∑–∞ embeddings

**–ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (cosine similarity):**
```python
import numpy as np

def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

# –ü—Ä–∏–º–µ—Ä
cat_vector = [0.8, 0.3, -0.1]
kitten_vector = [0.79, 0.31, -0.09]
dog_vector = [0.7, -0.2, 0.4]

similarity_cat_kitten = cosine_similarity(cat_vector, kitten_vector)
# 0.998 (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏!)

similarity_cat_dog = cosine_similarity(cat_vector, dog_vector)
# 0.612 (–º–µ–Ω–µ–µ –ø–æ—Ö–æ–∂–∏)
```

**–ó–Ω–∞—á–µ–Ω–∏—è:**
- 1.0 = –∞–±—Å–æ–ª—é—Ç–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ
- 0.9-0.99 = –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–µ
- 0.7-0.89 = –ø–æ—Ö–æ–∂–∏–µ
- < 0.7 = —Ä–∞–∑–Ω—ã–µ

---

## üîç –ß–∞—Å—Ç—å 2: Semantic Search (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫)

### Keyword Search vs Semantic Search

#### Keyword Search (–æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫)

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
```sql
-- –ò—â–µ—Ç —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
SELECT * FROM lessons 
WHERE content LIKE '%Server Actions%'
```

**–ü—Ä–∏–º–µ—Ä:**
```
–ó–∞–ø—Ä–æ—Å: "Server Actions"

–ù–∞–π–¥—ë—Ç:
‚úÖ "Server Actions ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏..."
‚úÖ "Next.js Server Actions —Ä–∞–±–æ—Ç–∞—é—Ç..."

–ù–ï –Ω–∞–π–¥—ë—Ç:
‚ùå "–§—É–Ω–∫—Ü–∏–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ Next.js" (–¥—Ä—É–≥–∏–µ —Å–ª–æ–≤–∞)
‚ùå "–°–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏" (—Å–∏–Ω–æ–Ω–∏–º)
```

**–ü—Ä–æ–±–ª–µ–º–∞:** –ù—É–∂–Ω–æ —É–≥–∞–¥–∞—Ç—å —Ç–æ—á–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —É—Ä–æ–∫–∞!

---

#### Semantic Search (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫)

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
```python
# 1. –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –∑–∞–ø—Ä–æ—Å –≤ –≤–µ–∫—Ç–æ—Ä
query_vector = embedding("Server Actions")

# 2. –ò—â–µ–º –≤–µ–∫—Ç–æ—Ä—ã —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º
similar_vectors = vector_db.search(
    query_vector, 
    top_k=3  # –¢–æ–ø-3 –ø–æ—Ö–æ–∂–∏—Ö
)
```

**–ü—Ä–∏–º–µ—Ä:**
```
–ó–∞–ø—Ä–æ—Å: "Server Actions"
Query vector: [0.2, -0.5, 0.8, ...]

–ù–∞–π–¥—ë—Ç:
‚úÖ "Server Actions ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏..." (0.95 similarity)
‚úÖ "–§—É–Ω–∫—Ü–∏–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ Next.js" (0.87 similarity)
‚úÖ "–°–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ Next.js" (0.83 similarity)

–ü–æ–Ω–∏–º–∞–µ—Ç –°–ú–´–°–õ, –Ω–µ —Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞!
```

### –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ

```
KEYWORD SEARCH:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ó–∞–ø—Ä–æ—Å: "Server Actions"           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ò—â–µ—Ç —Å—Ç—Ä–æ–∫—É "Server Actions"       ‚îÇ
‚îÇ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
–ù–∞–π–¥–µ–Ω–æ: 5 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚úÖ


SEMANTIC SEARCH:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –ó–∞–ø—Ä–æ—Å: "Server Actions"           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Embedding: [0.2, -0.5, 0.8, ...]   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Vector DB: –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä—ã ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
–ù–∞–π–¥–µ–Ω–æ:
- "Server Actions" (0.95)
- "–§—É–Ω–∫—Ü–∏–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ" (0.87)  ‚Üê –¥—Ä—É–≥–∏–µ —Å–ª–æ–≤–∞!
- "–°–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏" (0.83)   ‚Üê —Å–∏–Ω–æ–Ω–∏–º!
= 12 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚úÖ (–±–æ–ª—å—à–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
```

---

## üóÑÔ∏è –ß–∞—Å—Ç—å 3: –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö

### –û–±—ã—á–Ω–∞—è –ë–î vs –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î

| **–ê—Å–ø–µ–∫—Ç** | **PostgreSQL (–æ–±—ã—á–Ω–∞—è –ë–î)** | **–í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î** |
|---|---|---|
| **–ß—Ç–æ —Ö—Ä–∞–Ω–∏—Ç** | –°—Ç—Ä–æ–∫–∏, —á–∏—Å–ª–∞, JSON | –í–µ–∫—Ç–æ—Ä—ã (–º–∞—Å—Å–∏–≤—ã —á–∏—Å–µ–ª) |
| **–ü–æ–∏—Å–∫** | `WHERE title = 'X'` | Similarity search |
| **–ò–Ω–¥–µ–∫—Å** | B-tree, Hash | HNSW, IVF |
| **–î–ª—è —á–µ–≥–æ** | CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏ | Semantic search |
| **–ü—Ä–∏–º–µ—Ä** | –ù–∞–π—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID | –ù–∞–π—Ç–∏ –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã |

### –¢—Ä–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î

#### 1. pgvector (PostgreSQL extension)

**–ß—Ç–æ —ç—Ç–æ:**
- –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è PostgreSQL
- –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö `vector`
- –í—Å—Ç—Ä–æ–µ–Ω–æ –≤ —Ç–≤–æ—é —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ë–î

**–ü–ª—é—Å—ã:**
- ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ
- ‚úÖ –£–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å PostgreSQL
- ‚úÖ –ù–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
- ‚úÖ ACID —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏

**–ú–∏–Ω—É—Å—ã:**
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –¥–ª—è >1M –≤–µ–∫—Ç–æ—Ä–æ–≤
- ‚ùå –†—É—á–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```sql
-- –í PostgreSQL
CREATE EXTENSION vector;

-- –°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏
CREATE TABLE lesson_embeddings (
    id SERIAL PRIMARY KEY,
    lesson_id INTEGER,
    content TEXT,
    embedding VECTOR(1536)  -- OpenAI —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
);

-- –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
CREATE INDEX ON lesson_embeddings 
USING ivfflat (embedding vector_cosine_ops);
```

**–ü—Ä–∏–º–µ—Ä –ø–æ–∏—Å–∫–∞:**
```sql
-- –ù–∞–π—Ç–∏ —Ç–æ–ø-3 –ø–æ—Ö–æ–∂–∏—Ö —É—Ä–æ–∫–∞
SELECT lesson_id, content, 
       1 - (embedding <=> '[0.2, -0.5, ...]') AS similarity
FROM lesson_embeddings
ORDER BY embedding <=> '[0.2, -0.5, ...]'
LIMIT 3;
```

---

#### 2. Pinecone (managed service)

**–ß—Ç–æ —ç—Ç–æ:**
- –û–±–ª–∞—á–Ω–∞—è –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î
- Managed (–Ω–µ –Ω—É–∂–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å)
- API –¥–ª—è —Ä–∞–±–æ—Ç—ã

**–ü–ª—é—Å—ã:**
- ‚úÖ –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞)
- ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π API
- ‚úÖ Dashboard –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

**–ú–∏–Ω—É—Å—ã:**
- ‚ùå –°—Ç–æ–∏—Ç $70/–º–µ—Å—è—Ü (–º–∏–Ω–∏–º—É–º)
- ‚ùå –î–∞–Ω–Ω—ã–µ —É —Ç—Ä–µ—Ç—å–µ–π —Å—Ç–æ—Ä–æ–Ω—ã

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install pinecone-client
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
import pinecone

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
pinecone.init(api_key="YOUR_API_KEY", environment="us-west1-gcp")

# –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
pinecone.create_index(
    name="ai-web-learning",
    dimension=1536,  # OpenAI embedding size
    metric="cosine"
)

# –ü–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∏–Ω–¥–µ–∫—Å—É
index = pinecone.Index("ai-web-learning")

# –î–æ–±–∞–≤–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã
index.upsert(vectors=[
    ("lesson-1-1", [0.2, -0.5, ...], {"title": "Client-Server"}),
    ("lesson-1-2", [0.3, -0.4, ...], {"title": "HTTP Protocol"})
])

# –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
results = index.query(
    vector=[0.25, -0.45, ...],  # Query embedding
    top_k=3,
    include_metadata=True
)
```

---

#### 3. ChromaDB (self-hosted)

**–ß—Ç–æ —ç—Ç–æ:**
- –í–µ–∫—Ç–æ—Ä–Ω–∞—è –ë–î –Ω–∞ Python
- –õ–æ–∫–∞–ª—å–Ω–∞—è –∏–ª–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
- –û—Ç–∫—Ä—ã—Ç—ã–π –∫–æ–¥

**–ü–ª—é—Å—ã:**
- ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ
- ‚úÖ –õ–µ–≥–∫–æ –Ω–∞—á–∞—Ç—å (pip install)
- ‚úÖ –•–æ—Ä–æ—à–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

**–ú–∏–Ω—É—Å—ã:**
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ Pinecone
- ‚ùå –ù—É–∂–Ω–æ —Å–∞–º–æ–º—É –¥–µ–ø–ª–æ–∏—Ç—å

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install chromadb
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```python
import chromadb

# –°–æ–∑–¥–∞—Ç—å –∫–ª–∏–µ–Ω—Ç
client = chromadb.Client()

# –°–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é
collection = client.create_collection("ai-web-learning")

# –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã
collection.add(
    documents=["Server Actions ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏...", "REST API ‚Äî —ç—Ç–æ..."],
    metadatas=[{"lesson": "8.2"}, {"lesson": "1.4"}],
    ids=["lesson-8-2", "lesson-1-4"]
)

# –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö
results = collection.query(
    query_texts=["–ß—Ç–æ —Ç–∞–∫–æ–µ Server Actions?"],
    n_results=3
)
```

---

### –ö–∞–∫—É—é –≤—ã–±—Ä–∞—Ç—å?

| **–°—Ü–µ–Ω–∞—Ä–∏–π** | **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è** |
|---|---|
| **–ù–∞—á–∞–ª–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏** | ChromaDB (–±—ã—Å—Ç—Ä–æ —Å—Ç–∞—Ä—Ç–æ–≤–∞—Ç—å) |
| **Production (<100K –≤–µ–∫—Ç–æ—Ä–æ–≤)** | pgvector (–±–µ—Å–ø–ª–∞—Ç–Ω–æ) |
| **Production (>1M –≤–µ–∫—Ç–æ—Ä–æ–≤)** | Pinecone (—Å–∫–æ—Ä–æ—Å—Ç—å) |
| **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π –±—é–¥–∂–µ—Ç** | pgvector ‚úÖ |
| **–ù—É–∂–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å** | Pinecone |

**–î–ª—è —Ç–≤–æ–µ–π —à–∫–æ–ª—ã (500 —É—Ä–æ–∫–æ–≤ ‚âà 5000 –≤–µ–∫—Ç–æ—Ä–æ–≤):**
‚Üí **pgvector** –∏–¥–µ–∞–ª—å–Ω–æ! ‚úÖ

---

## üîß –ß–∞—Å—Ç—å 4: –°–æ–∑–¥–∞–Ω–∏–µ Embeddings —Å OpenAI

### OpenAI Embeddings API

**–ú–æ–¥–µ–ª—å:** `text-embedding-ada-002`
- –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: 1536
- –°—Ç–æ–∏–º–æ—Å—Ç—å: $0.0001 –∑–∞ 1K —Ç–æ–∫–µ–Ω–æ–≤
- –õ–∏–º–∏—Ç: 8191 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å

### –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
pip install openai
```

**–°–æ–∑–¥–∞–Ω–∏–µ embedding:**
```python
# backend/embeddings/create.py
import openai
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

def create_embedding(text: str) -> list[float]:
    """–°–æ–∑–¥–∞—Ç—å embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    response = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=text
    )
    
    embedding = response['data'][0]['embedding']
    return embedding

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
text = "Server Actions ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ Next.js..."
vector = create_embedding(text)

print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(vector)}")  # 1536
print(f"–ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–µ–Ω–∏–π: {vector[:5]}")
# [0.234, -0.567, 0.890, -0.123, 0.456]
```

### Batch processing (–ø–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)

**–î–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏:**
```python
def create_embeddings_batch(texts: list[str]) -> list[list[float]]:
    """–°–æ–∑–¥–∞—Ç—å embeddings –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤"""
    response = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=texts  # –ú–æ–∂–Ω–æ –¥–æ 2048 —Ç–µ–∫—Å—Ç–æ–≤ –∑–∞ —Ä–∞–∑
    )
    
    embeddings = [item['embedding'] for item in response['data']]
    return embeddings

# –ü—Ä–∏–º–µ—Ä
texts = [
    "–£—Ä–æ–∫ 1.1: Client-Server –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞...",
    "–£—Ä–æ–∫ 1.2: HTTP –ø—Ä–æ—Ç–æ–∫–æ–ª...",
    "–£—Ä–æ–∫ 1.3: JSON —Ñ–æ—Ä–º–∞—Ç..."
]

vectors = create_embeddings_batch(texts)
# –ë—ã—Å—Ç—Ä–µ–µ —á–µ–º 3 –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞!
```

---

## üì¶ –ß–∞—Å—Ç—å 5: –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞

### Chunking (—Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏)

**–ü—Ä–æ–±–ª–µ–º–∞:** –£—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω—ã–µ (2000+ —Å–ª–æ–≤), –∞ embedding –º–æ–¥–µ–ª—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ (8191 —Ç–æ–∫–µ–Ω–æ–≤).

**–†–µ—à–µ–Ω–∏–µ:** –†–∞–∑–±–∏—Ç—å —É—Ä–æ–∫ –Ω–∞ chunks (—á–∞—Å—Ç–∏) –ø–æ 1000 —Ç–æ–∫–µ–Ω–æ–≤.

**–ö–æ–¥:**
```python
# backend/embeddings/chunking.py
from langchain.text_splitter import RecursiveCharacterTextSplitter

def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200):
    """–†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ chunks —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    
    chunks = splitter.split_text(text)
    return chunks

# –ü—Ä–∏–º–µ—Ä
lesson_text = """
# –£—Ä–æ–∫ 1.1: Client-Server –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

## –í–≤–µ–¥–µ–Ω–∏–µ
Client-Server –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞...
[2000 —Å–ª–æ–≤]
"""

chunks = chunk_text(lesson_text)
print(f"–£—Ä–æ–∫ —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} chunks")
# –£—Ä–æ–∫ —Ä–∞–∑–±–∏—Ç –Ω–∞ 3 chunks

for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤")
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `chunk_size=1000` ‚Äî —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ (~750 —Ç–æ–∫–µ–Ω–æ–≤)
- `overlap=200` ‚Äî –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)

**–ü–æ—á–µ–º—É overlap?**
```
Chunk 1: "...Server Actions –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ."
              ‚îî‚îÄ overlap ‚îÄ‚îê
Chunk 2:      "–Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ. Next.js –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏..."
                          
–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —Ä–∞–∑–æ—Ä–≤–∞–Ω–æ!
```

---

### –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

**–ö–æ–¥:**
```python
# backend/embeddings/index_lessons.py
import openai
from database import db
from chunking import chunk_text

async def index_lesson(lesson_id: int, content: str):
    """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –æ–¥–∏–Ω —É—Ä–æ–∫"""
    
    # 1. –†–∞–∑–±–∏—Ç—å –Ω–∞ chunks
    chunks = chunk_text(content)
    
    # 2. –°–æ–∑–¥–∞—Ç—å embeddings –¥–ª—è –≤—Å–µ—Ö chunks
    embeddings = []
    for chunk in chunks:
        embedding = create_embedding(chunk)
        embeddings.append(embedding)
    
    # 3. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î (pgvector)
    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
        await db.lesson_embeddings.create({
            "lesson_id": lesson_id,
            "chunk_index": i,
            "content": chunk,
            "embedding": embedding
        })
    
    print(f"Lesson {lesson_id} indexed: {len(chunks)} chunks")

# –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —É—Ä–æ–∫–∏
async def index_all_lessons():
    lessons = await db.lessons.find_many()
    
    for lesson in lessons:
        print(f"Indexing lesson {lesson.id}...")
        await index_lesson(lesson.id, lesson.content)
    
    print(f"‚úÖ Indexed {len(lessons)} lessons")
```

**–ó–∞–ø—É—Å–∫:**
```bash
python -m backend.embeddings.index_lessons
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
Indexing lesson 1...
Lesson 1 indexed: 3 chunks
Indexing lesson 2...
Lesson 2 indexed: 2 chunks
...
‚úÖ Indexed 500 lessons (1,847 chunks total)
```

---

## üîé –ß–∞—Å—Ç—å 6: Semantic Search —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î

### –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö chunks

**–ö–æ–¥:**
```python
# backend/rag/search.py
import openai
from database import db

async def search_relevant_chunks(query: str, top_k: int = 3):
    """–ù–∞–π—Ç–∏ —Ç–æ–ø-K —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö chunks –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
    
    # 1. –°–æ–∑–¥–∞—Ç—å embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
    query_embedding = create_embedding(query)
    
    # 2. –ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î (pgvector)
    results = await db.execute(f"""
        SELECT 
            lesson_id,
            chunk_index,
            content,
            1 - (embedding <=> '{query_embedding}') AS similarity
        FROM lesson_embeddings
        ORDER BY embedding <=> '{query_embedding}'
        LIMIT {top_k}
    """)
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
query = "–ß—Ç–æ —Ç–∞–∫–æ–µ Server Actions –≤ Next.js?"
results = await search_relevant_chunks(query, top_k=3)

for result in results:
    print(f"Lesson {result['lesson_id']}, Chunk {result['chunk_index']}")
    print(f"Similarity: {result['similarity']:.3f}")
    print(f"Content: {result['content'][:100]}...")
    print()
```

**–í—ã–≤–æ–¥:**
```
Lesson 82, Chunk 2
Similarity: 0.924
Content: Server Actions ‚Äî —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ Next.js –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è 
–Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ...

Lesson 81, Chunk 5
Similarity: 0.887
Content: –í Next.js Full-Stack –ø–æ–¥—Ö–æ–¥–µ, Server Actions –∑–∞–º–µ–Ω—è—é—Ç 
—Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ REST API endpoints...

Lesson 80, Chunk 3
Similarity: 0.854
Content: –ú–æ–Ω–æ–ª–∏—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Next.js –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ 
—Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é...
```

---

## üìä –ß–∞—Å—Ç—å 7: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞

### –ö–∞–∫ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ?

**1. Similarity score**
```
> 0.9  = –æ—á–µ–Ω—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ ‚úÖ
0.8-0.9 = —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ ‚úÖ
0.7-0.8 = –≤–æ–∑–º–æ–∂–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ ‚ö†Ô∏è
< 0.7  = –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ ‚ùå
```

**2. Manual evaluation**
```python
# –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
test_queries = [
    "–ß—Ç–æ —Ç–∞–∫–æ–µ REST API?",
    "–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å FastAPI endpoint?",
    "–†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É SSR –∏ CSR?"
]

for query in test_queries:
    print(f"\nQuery: {query}")
    results = await search_relevant_chunks(query, top_k=3)
    
    for i, result in enumerate(results, 1):
        print(f"{i}. Lesson {result['lesson_id']} (score: {result['similarity']:.3f})")
        print(f"   {result['content'][:100]}...")
    
    # –í—Ä—É—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä—å: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ª–∏ —É—Ä–æ–∫–∏ –Ω–∞—à–ª–∏—Å—å?
```

**3. A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**
- –ó–∞–ø—É—Å—Ç–∏ RAG —Å–∏—Å—Ç–µ–º—É –¥–ª—è —á–∞—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
- –°–æ–±–∏—Ä–∞–π –º–µ—Ç—Ä–∏–∫–∏: thumbs up/down, time on page
- –°—Ä–∞–≤–Ω–∏ —Å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π –≥—Ä—É–ø–ø–æ–π

---

## üéØ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ

### –¶–µ–ª—å: –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ç–≤–æ–∏ —É—Ä–æ–∫–∏

**–®–∞–≥–∏:**

**1. –ù–∞—Å—Ç—Ä–æ–π pgvector**
```sql
-- –í PostgreSQL
CREATE EXTENSION vector;

CREATE TABLE lesson_embeddings (
    id SERIAL PRIMARY KEY,
    lesson_id INTEGER REFERENCES lessons(id),
    chunk_index INTEGER,
    content TEXT,
    embedding VECTOR(1536),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX ON lesson_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**2. –°–æ–∑–¥–∞–π —Å–∫—Ä–∏–ø—Ç –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏**
```python
# backend/scripts/index_all.py
import asyncio
from backend.embeddings.index_lessons import index_all_lessons

async def main():
    await index_all_lessons()

if __name__ == "__main__":
    asyncio.run(main())
```

**3. –ó–∞–ø—É—Å—Ç–∏**
```bash
export OPENAI_API_KEY="sk-..."
python backend/scripts/index_all.py
```

**4. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π –ø–æ–∏—Å–∫**
```python
# backend/scripts/test_search.py
from backend.rag.search import search_relevant_chunks

query = "–û–±—ä—è—Å–Ω–∏ —á—Ç–æ —Ç–∞–∫–æ–µ embeddings"
results = await search_relevant_chunks(query, top_k=5)

for result in results:
    print(f"Lesson {result['lesson_id']}: {result['similarity']:.3f}")
```

---

## üéì –†–µ–∑—é–º–µ —É—Ä–æ–∫–∞

### –ß—Ç–æ —Ç–∞–∫–æ–µ Embeddings

**Embeddings = –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª**
```
"Server Actions" ‚Üí [0.2, -0.5, 0.8, ..., 1536 —á–∏—Å–µ–ª]
```

### Semantic Search

**–ü–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É, –∞ –Ω–µ –ø–æ —Å–ª–æ–≤–∞–º:**
```
Query: "Server Actions"
–ù–∞–π–¥—ë—Ç:
‚úÖ "Server Actions"
‚úÖ "–§—É–Ω–∫—Ü–∏–∏ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ"
‚úÖ "–°–µ—Ä–≤–µ—Ä–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"
```

### –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –ë–î

| **–ë–î** | **–î–ª—è —á–µ–≥–æ** | **–°—Ç–æ–∏–º–æ—Å—Ç—å** |
|---|---|---|
| pgvector | <100K –≤–µ–∫—Ç–æ—Ä–æ–≤ | –ë–µ—Å–ø–ª–∞—Ç–Ω–æ ‚úÖ |
| Pinecone | >1M –≤–µ–∫—Ç–æ—Ä–æ–≤ | $70/–º–µ—Å |
| ChromaDB | –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ | –ë–µ—Å–ø–ª–∞—Ç–Ω–æ |

### –ü—Ä–æ—Ü–µ—Å—Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏

```
–£—Ä–æ–∫ ‚Üí Chunking ‚Üí Embeddings ‚Üí Vector DB
                                    ‚Üì
Query ‚Üí Query Embedding ‚Üí Similarity Search ‚Üí –¢–æ–ø-K chunks
```

### –î–ª—è —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

**500 —É—Ä–æ–∫–æ–≤ ‚âà 1,847 chunks:**
- –°—Ç–æ–∏–º–æ—Å—Ç—å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: ~$1
- –•—Ä–∞–Ω–µ–Ω–∏–µ: pgvector (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
- –ü–æ–∏—Å–∫: <100ms

---

## üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–Ω–∏–º–∞–Ω–∏—è

1. **–ß—Ç–æ —Ç–∞–∫–æ–µ embedding?**
   - –û—Ç–≤–µ—Ç: –í–µ–∫—Ç–æ—Ä —á–∏—Å–µ–ª (1536) –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏–π —Å–º—ã—Å–ª —Ç–µ–∫—Å—Ç–∞

2. **–ß–µ–º semantic search –ª—É—á—à–µ keyword search?**
   - –û—Ç–≤–µ—Ç: –ü–æ–Ω–∏–º–∞–µ—Ç —Å–º—ã—Å–ª, –Ω–∞—Ö–æ–¥–∏—Ç —Å–∏–Ω–æ–Ω–∏–º—ã, –Ω–µ –Ω—É–∂–Ω–æ —É–≥–∞–¥—ã–≤–∞—Ç—å —Å–ª–æ–≤–∞

3. **–ö–∞–∫—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î –≤—ã–±—Ä–∞—Ç—å –¥–ª—è 500 —É—Ä–æ–∫–æ–≤?**
   - –û—Ç–≤–µ—Ç: pgvector (–±–µ—Å–ø–ª–∞—Ç–Ω–æ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±—ã—Å—Ç—Ä–æ)

4. **–ó–∞—á–µ–º –Ω—É–∂–µ–Ω chunking?**
   - –û—Ç–≤–µ—Ç: –£—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω—ã–µ, embedding –º–æ–¥–µ–ª—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞ 8191 —Ç–æ–∫–µ–Ω–∞–º–∏

5. **–ß—Ç–æ —Ç–∞–∫–æ–µ overlap –≤ chunking?**
   - –û—Ç–≤–µ—Ç: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É chunks —á—Ç–æ–±—ã –Ω–µ —Ä–∞–∑–æ—Ä–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥

–í **–£—Ä–æ–∫–µ 9.2** –º—ã –∏–∑—É—á–∏–º:
- **LangChain** ‚Äî —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è RAG
- **Document Loaders** ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ —É—Ä–æ–∫–æ–≤
- **Retrieval QA Chain** ‚Äî —Ü–µ–ø–æ—á–∫–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
- **Memory** ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
- **–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã**

**–ì–æ—Ç–æ–≤ —Å–≤—è–∑–∞—Ç—å –≤—Å—ë –≤–º–µ—Å—Ç–µ —Å LangChain?** üéØ

---

**–ö–æ–Ω–µ—Ü —É—Ä–æ–∫–∞ 9.1** ‚úÖ
